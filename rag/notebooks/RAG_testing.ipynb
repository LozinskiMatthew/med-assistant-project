{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:47:54.891090Z",
     "start_time": "2025-07-16T05:47:54.882020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from jedi.inference.gradual.typing import TypedDict\n",
    "\n",
    "# Construct path two directories up from the **current working directory**\n",
    "env_path = Path.cwd().resolve().parents[1] / '.env'\n",
    "\n",
    "# Load .env from that path\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "cohere_api_key = os.getenv('COHERE_API_KEY')\n",
    "if cohere_api_key is None:\n",
    "    raise ValueError(\"COHERE_API_KEY not set in .env\")\n",
    "\n",
    "#print(cohere_api_key)  # For debug only\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "if groq_api_key is None:\n",
    "    raise ValueError(\"GROQ_API_KEY not set in .env\")\n",
    "\n",
    "# Optional: explicitly set in os.environ if required by libraries\n",
    "os.environ['COHERE_API_KEY'] = cohere_api_key\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key\n"
   ],
   "id": "d1ca41fb1d9c0cc9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:47:54.967963Z",
     "start_time": "2025-07-16T05:47:54.962749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Starting from your current working directory\n",
    "base_dir = os.getcwd()  # or set explicitly\n",
    "\n",
    "user_id = 1 # In future I should get this via API\n",
    "\n",
    "# Build the path\n",
    "media_path = os.path.join(base_dir, \"media\", \"documents\", f\"user_{user_id}\")\n",
    "\n",
    "print(\"Full path:\", media_path)\n",
    "\n",
    "#with open(os.path.join(media_path, \"Lab0_Laravel11.pdf\")) as f:\n",
    "#    text = f.read()\n"
   ],
   "id": "4db7fab35b6984e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path: /home/matthew/Desktop/med-assistant-project/rag/notebooks/media/documents/user_1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:48:02.329216Z",
     "start_time": "2025-07-16T05:48:01.089733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install the splitter module (if needed)\n",
    "# pip install -qU langchain-text-splitters\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#print(media_path)\n",
    "\n",
    "# For testing in ipynb\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf')\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1800,         # max characters per chunk\n",
    "    chunk_overlap=300,       # overlap between chunks\n",
    "    length_function=len,    # use character count\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # split hierarchy\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# Inspect first couple of chunks:\n",
    "print(docs[7])"
   ],
   "id": "295457aceb92f0c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/miniconda3/envs/ML_REST/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='7 \n",
      "Zintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \n",
      " \n",
      "Laravel Breeze  domyślnie generuje strony za pomocą wi doków Blade, ale m ożna \n",
      "skonfigurować go do wykorzystania widoków wykorzystujących Vue, React lub Inertia. \n",
      "Najprostsza konfiguracja korzysta z domyślego silnika widoków Blade.  Ten silnik oraz \n",
      "Breeze wskazaliśmy przy tworzeniu nowego projektu. \n",
      " \n",
      "Aby poprawnie działało uwierzytelnienie użytkownika, należy wykorzystać (utworzone już \n",
      "w tym celu przez Laravel) elementy związane z zapisem danych użytkownika w bazie danych \n",
      "(domyślnie MySQL) . W celu ustawienia połączenia do bazy danych, w pliku .env \n",
      "(w głównym folderze projektu) należy podać dane autoryzujące dostęp do bazy danych. Dla \n",
      "MySQL domyślne ustawienia w pliku .env (DB_CONNECTION, DB_HOST, itd.) są już \n",
      "gotowe (Rys. 12.8). \n",
      " \n",
      " \n",
      "Rys. 12.8. Domyślne ustawienia połączenia do bazy o nazwie lab12 na serwerze MySQL \n",
      "Korzystając z narzędzia phpMyAdmin utwórz nową bazę danych o nazwie lab12 (taka nazwa \n",
      "bazy podana jest jako domyślna w ustawieniu DB_DATABASE=lab12 (Rys. 12.8). \n",
      "Do pracy z bazą danych wykorzystamy tzw. migracje. Migracje to pliki wykonuj ące \n",
      "określone operacje na bazie danych, takie jak np. tworzenie tabel.  \n",
      "Pliki migracji  znajdują się w katalogu database/migrations. Laravel zadbał już o to, by \n",
      "utworzyć odpowiedni plik migracji dla tabeli użytkowników  users. Gotowe pliki migracji \n",
      "można podejrzeć w projekcie ( Rys. 12.9). Migracja z Rys. 12.9 tworzy tabelę users. Nazwy \n",
      "i typy pól tabeli (kolumn) zdefiniowano bezpośrednio z poziomu kodu w metodzie up() klasy \n",
      "o nazwie CreateUserTable, która dziedziczy po klasie Migration.' metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:32:24.966975Z",
     "start_time": "2025-07-14T16:32:24.962124Z"
    }
   },
   "cell_type": "code",
   "source": "type(docs[1])",
   "id": "d03611be9ba73470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:32:25.052275Z",
     "start_time": "2025-07-14T16:32:25.047785Z"
    }
   },
   "cell_type": "code",
   "source": "type(docs[1])",
   "id": "ca0ae8bda60e8b48",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:50:39.805665Z",
     "start_time": "2025-07-16T05:50:38.773502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "text_inputs = [\n",
    "    {\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"{docs[7]}\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "response = co.embed(\n",
    "    inputs=text_inputs,\n",
    "    model=\"embed-v4.0\",\n",
    "    input_type=\"classification\",\n",
    "    embedding_types=[\"float\"],\n",
    ")\n",
    "print(response)\n"
   ],
   "id": "a261a2643522dadc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='d247232e-ed3a-4d43-8ab9-0cb24e28b4b6' embeddings=EmbedByTypeResponseEmbeddings(float_=[[0.008361816, -0.0045776367, -0.018432617, 0.0021972656, 0.00075912476, -0.0061035156, -0.0034942627, 0.016967773, -0.017456055, 0.030273438, -0.039794922, 0.072265625, -0.05883789, 0.0012054443, -0.020874023, 0.004760742, -0.024169922, -0.008178711, 0.015197754, -0.0019302368, 0.05810547, -0.020385742, 0.0015106201, -0.02758789, 0.017456055, 0.0014038086, 0.02709961, 0.009643555, 0.032226562, -0.02734375, -0.007659912, -0.024291992, -0.001083374, 0.0061035156, -0.09033203, -0.010864258, 0.013000488, -0.040283203, -0.028930664, 0.012268066, -0.013061523, -0.008728027, 0.024536133, 0.032470703, -0.045410156, -0.010009766, 0.014160156, -0.016235352, -0.052246094, 0.00051498413, 0.020629883, 0.025756836, -0.006378174, -0.026855469, 0.04345703, 0.024047852, -0.0013046265, 0.003753662, -0.030273438, 0.02746582, -0.0032348633, 0.04711914, 0.04296875, -0.0009727478, -0.044433594, 0.010375977, -0.030395508, 0.0008583069, 0.022460938, 0.001663208, -0.005126953, -0.029052734, -0.022460938, 0.022460938, 0.017089844, -0.030883789, -0.0028533936, -0.046142578, -0.013183594, -0.024414062, 0.004699707, 0.027709961, 0.016601562, 0.04711914, 0.0037841797, -0.009399414, 0.004638672, 0.006072998, -0.016357422, 0.0154418945, 0.001914978, 0.009033203, -0.05419922, -0.006011963, 0.0061950684, 0.041748047, -0.0015640259, 0.01586914, 0.03466797, 0.00491333, 0.013916016, -0.00065231323, 0.0018005371, 0.021728516, -0.019897461, -0.024047852, -0.0007019043, 0.019165039, -0.022338867, -0.026000977, 0.0036773682, -0.025024414, -0.018920898, -0.04321289, -0.032226562, -0.006164551, 0.0017242432, -0.004425049, -0.028442383, -0.033203125, -0.019165039, 0.008422852, -0.030639648, 0.0011901855, 0.0154418945, 0.017456055, 0.024169922, 0.028320312, 0.017211914, -0.013977051, -0.017456055, 0.03955078, -0.0008430481, 0.006378174, -0.025512695, -0.030639648, 0.011779785, -0.0013580322, -0.0028076172, -0.022094727, -0.0075683594, 0.037109375, -0.026367188, 0.01977539, 0.03955078, 0.009277344, 0.010131836, -0.012207031, -0.017944336, 0.02746582, -0.03149414, 0.024658203, 0.012023926, -0.010192871, -0.016601562, 0.032470703, 0.032958984, 0.0008010864, -0.0036010742, -0.000114917755, 0.03149414, 0.008544922, 0.013671875, 0.024414062, 0.03564453, -0.025878906, 0.028320312, -0.0068969727, -0.005340576, -0.032714844, 0.006286621, -0.014892578, 0.00982666, -0.0037841797, 0.040527344, -0.022094727, -0.010070801, 0.014465332, 0.036132812, 0.006866455, 0.00077056885, -0.04711914, 5.6505203e-05, -0.011230469, 0.04345703, -0.0040283203, -0.028076172, 0.010498047, -0.0012664795, -0.015563965, -0.012268066, 0.029174805, -0.006958008, 0.043945312, 0.009887695, -0.0020446777, -0.025634766, -0.03173828, 0.018798828, 0.011352539, 0.020141602, -0.015991211, 0.007232666, -0.005218506, 0.03540039, -0.012268066, 0.00491333, 0.031982422, -0.00970459, 0.0041503906, -0.016723633, -0.01965332, -0.0016937256, -0.029907227, -0.004852295, 0.030395508, 0.030273438, -0.0033874512, 0.0043945312, -0.045898438, -0.033935547, 0.014709473, -0.0234375, -0.009399414, -0.000957489, -0.07080078, 0.0074768066, 0.032470703, 0.0546875, -0.011657715, 0.010864258, -0.0019683838, -0.061279297, 0.038085938, 0.007293701, -0.0069274902, -0.01171875, 0.02355957, -0.016967773, -0.020996094, -0.03515625, 0.010559082, -0.0006752014, 0.028442383, 0.044921875, -0.052246094, 0.04248047, -0.008605957, -0.040771484, -0.03857422, 0.026000977, 0.011047363, 0.016723633, -0.025268555, 0.018188477, 0.015197754, 0.0035705566, 0.0010070801, 0.026855469, 0.018310547, -0.034179688, -0.020751953, 0.0008010864, 0.0061950684, -0.0031280518, 0.041992188, 0.048828125, 0.042236328, -0.0035552979, 0.017089844, -0.028198242, 0.024536133, -0.011291504, 0.017333984, -0.026123047, 0.043945312, 0.0034942627, -0.019897461, 0.03881836, 0.003753662, 0.010070801, 0.035888672, -0.00982666, 0.026977539, 0.03564453, -0.008605957, 0.041259766, -0.020996094, -0.0049743652, 0.0025634766, 0.03149414, -0.006500244, -0.017578125, 0.010864258, -0.040283203, 0.014221191, -0.015197754, -0.010314941, -0.010314941, 0.022583008, 0.024658203, -0.02331543, -0.026489258, 0.018920898, -0.0019302368, -0.016235352, -0.017333984, 0.07373047, -0.006866455, -0.0013961792, 0.03112793, -0.015136719, 0.022338867, 0.0014724731, 0.020629883, -0.004272461, -0.034179688, 0.002090454, 0.015197754, -0.026245117, 0.0026550293, 0.008728027, -0.004058838, 0.012390137, 0.025634766, -0.008605957, 0.029296875, 0.049316406, 0.055908203, -0.03173828, -0.026611328, -0.018798828, 0.0025634766, -0.043701172, -0.047851562, -0.00970459, 0.01361084, -0.0035552979, 0.052978516, -0.017456055, -0.0019302368, -0.013183594, -0.017089844, 0.003829956, -0.022583008, 0.006958008, -0.03540039, -0.00046730042, 0.021972656, -0.016723633, -0.022338867, -0.03112793, -0.015136719, 0.028564453, -0.017456055, 0.037597656, -0.007507324, 0.011169434, -0.032226562, -0.006378174, 0.011230469, 0.008911133, 0.0020446777, -0.022827148, 0.01586914, -0.012329102, 0.008544922, -0.0087890625, -0.011291504, 0.045654297, -0.00579834, 0.0058898926, 0.0063171387, 0.001159668, -0.0040283203, -0.0015869141, 0.051757812, 0.032958984, 0.029174805, 0.0037841797, -0.028930664, 0.012268066, -0.002380371, 0.013244629, 0.026367188, 0.0012969971, -0.016845703, -0.031982422, 0.034179688, 0.012817383, 0.005279541, -0.012634277, -0.01586914, -0.032226562, -0.043701172, -0.038330078, -0.037109375, 0.008728027, -0.0012817383, -0.004211426, 0.014099121, 0.024047852, -0.011108398, 0.029541016, 0.0049438477, -0.021484375, 0.0032043457, -0.011230469, 0.014343262, 0.009521484, -0.0010070801, -0.045654297, -0.019897461, 0.0028076172, 0.0019989014, -0.045898438, 0.0051879883, -0.0019836426, 0.013305664, -0.0043640137, 0.006866455, -0.026000977, -0.0115356445, -0.015014648, 0.0058288574, -0.0115356445, 0.00579834, -0.06591797, 0.022094727, 0.052978516, -0.017089844, -0.001373291, -0.02319336, 0.015197754, 0.034423828, -0.0034637451, 0.003753662, -0.052246094, 0.010131836, 0.0068359375, -0.061279297, -0.0059814453, 0.014892578, 0.045410156, 0.024169922, -0.010498047, -0.028686523, 0.049560547, 0.016723633, -0.015014648, -0.013122559, 0.007293701, 0.0064697266, -0.003036499, 0.009765625, 0.020874023, 0.008117676, -0.014831543, 0.040527344, -0.023803711, 0.024047852, -0.018798828, -0.02746582, 0.006134033, -0.024658203, -0.0002975464, -0.0073547363, 0.014892578, 0.0040283203, -0.0008125305, 0.0073547363, 0.016601562, -0.028442383, -0.013916016, 0.045166016, -0.0054016113, -0.0018234253, 0.021728516, -0.019165039, 0.029907227, 0.056396484, 0.01977539, 0.00091934204, 0.027832031, 0.019165039, 0.021240234, -0.0079956055, -0.041748047, -0.026245117, 0.025146484, -0.006500244, -0.010131836, 0.0051879883, 0.009216309, 0.00793457, 0.022949219, 0.010192871, -0.0037231445, -0.010009766, -0.032470703, 0.010253906, -0.043945312, -0.037841797, 0.012817383, 0.018432617, -0.03515625, -0.044677734, 0.0046081543, 0.023803711, -0.014160156, 0.03881836, -0.002456665, 0.019042969, -0.0072021484, 0.008422852, 0.021728516, 0.021728516, 0.0026245117, 0.067871094, -0.019897461, 0.002532959, -0.016845703, 0.013000488, -0.0073242188, -0.011962891, -0.041992188, -0.034423828, -0.0107421875, 0.00031089783, -0.041015625, -0.0030975342, 0.008300781, 0.0059814453, -0.0042419434, -0.049072266, -0.002822876, -0.024047852, -0.03173828, 0.030883789, -0.03173828, -0.01940918, -0.0032806396, -0.019165039, 0.03173828, 0.11035156, -0.018920898, 0.024414062, -0.010070801, -0.018066406, 0.03466797, 0.04663086, 0.015563965, -0.019165039, 0.00793457, 0.0035705566, 0.06689453, -0.02331543, 0.0071105957, 0.040527344, 0.084472656, -0.029907227, -0.008483887, -0.03173828, 0.02734375, 0.0067749023, 0.044677734, 0.0077819824, 0.04248047, 0.021972656, -0.025878906, 0.007873535, 0.03149414, 0.036132812, -0.0026855469, -0.027954102, 0.02746582, 0.018310547, -0.0061950684, 0.028198242, -0.008178711, 0.0032653809, 0.014038086, 0.0030059814, -0.0073547363, -0.024536133, 0.008239746, 0.025634766, 0.020996094, 0.038085938, 0.009155273, 0.01171875, -0.01361084, 0.014709473, -0.044677734, -0.018798828, 0.020141602, 0.012023926, 0.00982666, 0.006500244, -0.05908203, -0.038085938, 0.0018310547, 0.007598877, -0.018798828, -0.02722168, -0.004547119, -0.030273438, -0.039794922, 0.045166016, 0.039794922, 0.028686523, 0.0025634766, 0.040527344, 0.035888672, 0.024047852, -0.03491211, -0.018798828, 0.033691406, 0.009094238, 0.012451172, 0.011230469, -0.03857422, -0.030883789, -0.016357422, 0.044189453, 0.03149414, 0.02758789, 0.028930664, 0.04296875, 0.02331543, 0.0011138916, 0.032714844, -0.045410156, 0.0035095215, -0.011291504, 0.030883789, 0.001625061, -0.03857422, -0.0032653809, 0.0029907227, -0.008728027, 0.0027160645, 0.030395508, 0.014892578, -0.0071411133, -0.03149414, -0.02319336, -0.011413574, 0.012878418, -0.03173828, 0.009460449, -0.022705078, -0.008728027, -0.06542969, 0.025146484, 0.0033874512, 0.021728516, -0.018920898, 0.02355957, 0.033691406, -0.01171875, 0.020263672, -0.00982666, -0.072265625, 0.0035705566, 0.024536133, -0.0010757446, -0.036132812, -0.0019836426, -0.041259766, 1.859665e-05, -0.004058838, -0.014892578, 0.009155273, -0.007293701, -0.03173828, 0.0016784668, -0.00012397766, 0.03955078, 0.010131836, 0.013305664, -0.032714844, 0.03491211, -0.01159668, -0.038085938, 2.7537346e-05, -0.020996094, 0.037597656, -0.033447266, -0.0048217773, -0.017089844, -0.025634766, -0.01361084, -0.025756836, -0.0071105957, -0.0023345947, 0.014160156, 0.024169922, -0.01977539, -0.018798828, -0.012207031, -0.014038086, 0.012390137, -0.016357422, -0.0059509277, -0.00077438354, 0.01171875, 0.018066406, -0.021728516, 0.0107421875, -0.022705078, -0.022705078, -0.063964844, 0.027832031, -0.0073242188, -0.020507812, -0.012817383, -0.051757812, 0.026123047, -0.024902344, -0.0012130737, 0.002456665, 0.021606445, -0.012512207, -0.01977539, -0.00011730194, -0.024414062, -0.0022888184, 0.00039863586, 0.044677734, 0.009216309, 0.04272461, -0.04345703, 0.0020141602, 0.029785156, -0.032226562, -0.021728516, -0.009521484, -0.0048828125, 0.0054626465, -0.007873535, -0.010070801, -0.05029297, -0.041015625, -0.00032615662, 0.03173828, -0.01171875, 0.008056641, 0.03930664, 0.020874023, -0.013061523, -0.026977539, 0.0062561035, 0.0052490234, 0.021850586, 0.009399414, -9.6321106e-05, -0.024169922, -0.024291992, -0.050048828, -0.03881836, 0.0069274902, -0.008483887, -0.006713867, 0.014160156, 0.008911133, 0.010864258, -0.049072266, -0.020629883, 0.0010757446, 0.021240234, -0.049316406, 0.014221191, 0.011230469, -0.020019531, 0.025878906, -0.01940918, 0.005218506, -0.009338379, 0.014343262, 0.006652832, -0.028808594, 0.028076172, 0.014587402, -0.051757812, 0.01977539, -0.0027313232, 0.026367188, 0.02319336, 0.0031738281, -0.010131836, 0.011657715, 0.011047363, 0.018798828, -0.041503906, 0.007598877, -0.024658203, 0.04345703, 0.091308594, 0.005218506, -0.016113281, -0.008178711, -0.025756836, 0.029663086, -0.02734375, 0.0028686523, -0.064941406, 0.010009766, -0.0077209473, -0.012268066, 0.068359375, -0.0107421875, -0.018432617, -0.022094727, 0.029174805, -0.003250122, 0.016479492, -0.0095825195, -0.032958984, -0.0107421875, 0.015197754, -0.004119873, -0.0037384033, -0.052490234, 0.014221191, 0.01940918, -0.00982666, 0.009460449, 0.00030899048, -0.010253906, 0.048095703, 0.043945312, 0.05859375, 0.045410156, -0.003250122, 0.055664062, 0.0032348633, -0.02722168, -0.02758789, -0.020385742, -0.0017471313, 0.007507324, -0.0023040771, -0.028564453, 0.010192871, -0.037353516, -0.0002632141, 0.015197754, 0.0069274902, 0.006866455, -0.01965332, 0.025024414, -0.015136719, 0.0056762695, -0.036132812, 0.009399414, -0.00031089783, 0.033691406, 0.020141602, 0.015991211, 0.012023926, 0.010131836, 0.009399414, -0.030883789, -0.0064086914, -0.016113281, 0.011291504, -9.4890594e-05, -0.036132812, 0.008666992, -0.07910156, 0.019042969, -0.0015640259, -0.008728027, -0.0065307617, -0.030883789, 0.020996094, 0.01574707, 0.0022735596, -0.04321289, -0.013427734, -0.025878906, -0.0026245117, 0.0028686523, 0.006713867, 0.01940918, 0.030639648, 0.02758789, 0.033691406, -0.030029297, -0.0062561035, 0.015136719, -0.0031280518, 0.015136719, -0.016235352, 0.06689453, 0.02355957, 0.037841797, -0.0126953125, 0.041503906, 0.045898438, 0.047607422, -0.055908203, -0.009643555, -0.07373047, -0.0038909912, 0.013427734, -0.052001953, 0.025146484, 0.00793457, 0.033935547, -0.016113281, -0.0067443848, 0.01586914, -0.017578125, -0.008666992, 0.04711914, -0.007873535, -0.010192871, 0.006439209, -0.064941406, 0.038085938, 0.0028839111, -0.014526367, -0.012023926, 0.008666992, -0.044433594, -0.0037231445, -0.026367188, 0.0016555786, -0.032958984, 0.024536133, 0.02734375, 0.04736328, 0.0069274902, 0.006591797, -0.027709961, 0.00592041, -0.030395508, 0.01940918, 0.01574707, 0.055908203, 0.013061523, -0.07910156, -0.009521484, 0.004699707, 0.040771484, -0.0025787354, -0.018188477, -0.008056641, 0.024780273, 0.027832031, 0.037841797, 0.032226562, 0.006286621, -0.0042419434, 0.00030326843, 0.0055236816, 0.00024318695, 0.016967773, 0.02758789, -0.0015182495, 0.06347656, -0.055908203, -0.023803711, 0.021728516, 0.060791016, 0.0119018555, -0.025146484, 0.017456055, -0.020996094, -0.03149414, -0.006958008, 0.021850586, -0.008605957, 0.01965332, 0.010314941, -0.010314941, 0.033447266, 0.009155273, 0.008178711, 0.0004043579, 0.024658203, -0.011108398, 0.008117676, -0.008239746, 0.031982422, -0.0049438477, 0.003112793, -0.008483887, -0.03881836, 0.0063476562, 0.020019531, -0.028198242, 0.016357422, 0.018676758, 0.0043640137, 0.014099121, -0.0005378723, 0.026489258, -0.013122559, -0.01940918, -0.0041503906, 0.0037384033, 0.002380371, 0.009277344, -0.001449585, -0.01928711, 0.0067443848, 0.026733398, 0.03564453, 0.01965332, 0.010803223, -0.040771484, 0.021240234, -0.03857422, 0.036621094, 0.022338867, -0.026855469, 0.059326172, -0.03857422, 0.011352539, -0.05419922, 0.00592041, 0.028564453, -0.0015182495, -0.007659912, 0.052246094, 0.01373291, -0.029541016, -0.024658203, -0.035888672, 0.006164551, 0.00592041, 0.01159668, -0.00021362305, 0.028930664, -0.013061523, -0.0029296875, -0.048828125, -0.017333984, 0.020874023, 0.033935547, -0.027709961, 0.024902344, -0.0023651123, 0.015319824, 0.01586914, 0.009765625, -0.022216797, 0.016723633, 7.05719e-05, -0.026000977, -0.0018539429, 0.010009766, 0.012756348, 0.039794922, -0.029907227, 0.03515625, -0.007873535, -0.006500244, 0.0027770996, -0.061767578, 0.061279297, -0.0138549805, -0.0032043457, 0.019042969, -0.03930664, 0.036865234, -0.046142578, -0.04345703, -0.0011367798, -0.059326172, -0.0546875, -0.015197754, -0.012268066, 0.014038086, 0.071777344, 0.010009766, -0.026367188, -0.006378174, -0.0087890625, 0.03930664, 0.0022277832, -0.007598877, -0.013305664, 0.0126953125, -0.0003299713, 0.024047852, 0.026000977, -0.061279297, -0.050048828, -0.008666992, 0.02746582, 0.020263672, -0.014465332, -0.01574707, -0.006439209, 0.043701172, 0.026611328, 0.021240234, 0.012207031, 0.016113281, 0.0033569336, 0.05419922, 0.011413574, 0.029785156, 0.036865234, -0.009521484, 0.014709473, 0.0066223145, 0.0032806396, 0.044433594, 0.036376953, 0.032958984, -0.0062561035, -0.0234375, 0.025634766, 0.029296875, 0.009338379, 0.030883789, -0.029541016, -0.017822266, -0.02331543, -0.018798828, -0.001335144, -0.029541016, -0.03112793, -0.04321289, -0.013793945, -0.015014648, -0.0028839111, -0.021484375, -0.03112793, 0.0007972717, 0.034423828, 0.05493164, 0.0023651123, 0.005432129, -0.012512207, 0.0119018555, 0.037841797, -0.012329102, -0.051513672, -0.021850586, 0.004547119, 0.0027618408, 0.010375977, 0.025634766, -0.008117676, 0.00075531006, -0.011047363, -0.010864258, -0.01965332, -0.025268555, 0.008911133, 0.0146484375, 0.005004883, 0.008544922, 0.03955078, 0.036865234, 0.08984375, 0.040283203, 0.0015335083, 0.043945312, 0.009155273, -0.01586914, 0.031982422, -0.003829956, 0.0057373047, 0.003616333, 0.021972656, -0.016723633, -0.01953125, 0.0234375, 0.012268066, 0.01928711, -0.008056641, 0.0016784668, 0.021118164, 0.014038086, 0.012390137, 0.008422852, 0.037841797, -0.025390625, 0.00016880035, 0.03955078, -0.084472656, 0.019042969, -0.04321289, -0.024902344, -0.017944336, 0.0099487305, -0.007446289, 0.040771484, 0.0008049011, 0.030395508, 0.009338379, -0.041992188, 0.017700195, 0.011352539, 0.031982422, -0.013793945, 0.057617188, -0.008117676, -0.0049438477, 0.016845703, -0.045654297, -0.01940918, 0.04663086, 0.0046081543, -0.004180908, -0.043701172, 0.044189453, -0.022827148, -0.022094727, 0.0067749023, 0.0022125244, -0.014282227, -0.008972168, 0.007659912, -0.018188477, -0.013061523, 0.017456055, -0.030395508, 0.0015029907, -0.01977539, -0.0030670166, 0.027954102, 0.06225586, -0.006134033, 0.0030517578, 0.04296875, 0.039794922, -0.01586914, 0.00021266937, -0.0020141602, -0.015136719, -0.026123047, -0.0053710938, -0.013183594, 0.033203125, -0.00592041, -0.009338379, -0.024169922, 0.011962891, -0.033935547, -0.030273438, 0.032714844, -0.006591797, 0.008544922, -0.01940918, -0.040283203, -0.024902344, 0.008728027, -0.037841797, -0.0134887695, 0.012268066, 0.0016555786, 0.0030670166, -0.015197754, -0.012756348, -0.0067443848, 0.01928711, 0.018554688, 0.008972168, -0.022827148, 0.018554688, -0.059326172, 0.0008430481, -0.025756836, 0.034423828, -0.007598877, -0.007385254, -0.014465332, 0.021484375, -0.03491211, -0.014770508, -4.5776367e-05, -0.024414062, 0.03540039, 0.004272461, 0.006713867, -0.000667572, -0.047851562, -0.0031738281, 0.0011367798, 0.0077819824, 0.033447266, 0.033203125, 0.010009766, -0.026489258, 0.016601562, -0.015197754, -0.0015411377, 0.0023040771, 0.008239746, -0.0067443848, 0.028320312, -0.028320312, 0.037353516, 0.02319336, -0.02355957, 0.02355957, -0.048095703, 0.013244629, 0.056396484, -0.0030059814, -0.014770508, -0.0028839111, -0.05493164, 0.005432129, -0.010131836, -0.01373291, -0.014892578, -0.0004386902, 0.01586914, 0.028930664, -0.003967285, -0.008728027, 0.00025558472, 0.028930664, -0.005218506, -0.005859375, 0.018920898, 0.018188477, -0.017333984, 0.024536133, 0.03173828, -0.032470703, 0.024047852, 0.0046081543, 0.045898438, -0.05126953, -0.020385742, -0.026367188, 0.014953613, 0.009155273, 0.012512207, -0.028686523, -0.010009766, 0.017944336, 0.008361816, 0.003112793, -0.026489258, 0.032470703, 0.0012359619, 0.0009918213, 0.051757812, 0.0059509277, 0.014282227, -0.026611328, -0.032958984, 0.018432617, -0.015563965, -0.034179688, 0.016845703, 0.0016021729, 0.03540039, -0.029052734, -0.010864258, 0.052734375, -0.053466797, -1.7523766e-05, 0.022705078, 0.030395508, -0.01953125, 0.044189453, 0.027832031, -0.021972656, -0.040771484, -0.019042969, -0.016967773, -0.018310547, 0.0018386841, -0.0025482178, 0.003967285, -0.018554688, 0.008117676, 0.026000977, 0.013916016, 0.006225586, 0.023925781, -0.0107421875, 0.0053710938, 0.018798828, -0.03881836, 0.004211426, -0.016723633, -0.01373291, 0.022216797, -0.016357422, 0.01940918, -0.0095825195, -0.011047363, 0.013183594, 0.008972168, -0.022583008, -0.049072266, -0.02368164, 0.06982422, -0.007507324, -0.034179688, 0.053466797, -0.034179688, 0.034179688, 0.023925781, 0.014892578, -0.015136719, -0.0032653809, 0.01928711, 0.0033721924, 0.0016021729, -0.05102539, -0.029296875, 0.012268066, 0.005004883, -0.00064086914, -0.0059814453, -0.010131836, 0.0051574707, 0.03491211, 0.0077209473, 0.017089844, 0.011779785, -0.0006904602, -0.03881836, -0.012023926, -0.012878418, -0.011657715, -0.024047852, 0.041748047, 0.0027770996, -0.048095703, -0.004638672, 0.026123047, -0.01159668, -0.07080078, -0.00970459, 0.001045227, -0.030395508, -0.018066406, -0.03149414, 0.0025939941, -0.03491211, 0.0079956055, -0.010620117, -0.00061798096, -0.0030822754, -0.0060424805, 0.018554688, -0.0008621216, 0.0027770996, -0.010864258, 0.021118164, 0.0011978149, 0.011413574, -0.013122559, -0.0029907227, -0.026733398, -0.022827148, 0.056152344, 0.0027160645, 0.0012817383, -0.001373291, -0.004333496, 0.025390625, -0.032958984, -0.017089844, -0.020019531, -0.016479492, -0.0018920898, 0.03540039, -0.029174805, -0.009460449, -0.0048217773, 0.0014572144, 0.026489258, -0.0021362305, -0.01159668, -3.2186508e-05, 0.00012302399, -0.016235352, -0.02319336, -0.030395508, 0.020996094, -0.00010061264, -0.020141602, 0.0077209473, -0.013427734, 0.0007324219, -0.00037956238, 0.023071289, 0.028442383, 0.026855469, -0.0063476562, -0.047851562, 0.01953125, -0.045654297, -0.013916016, -0.009765625, -0.006866455, -0.02746582, 4.053116e-05, -0.044921875, -0.04711914, -0.01965332, -0.036865234, 0.005004883, -0.0073242188, -0.02746582, 0.00018787384, -0.018554688, -0.033691406, -0.020263672, 0.0011978149, 0.07519531, 0.008117676, 0.0134887695, -0.009155273, -0.018798828, 0.016113281, 0.010620117, 0.01953125, 0.033935547, -0.017578125, -0.00982666, 0.022705078, 0.025268555, 0.03564453, 0.0010223389, -0.004425049, 0.017944336, -0.0072631836, -0.023071289, -0.0067749023]], int8=None, uint8=None, binary=None, ubinary=None) texts=None images=None meta=ApiMeta(api_version=ApiMetaApiVersion(version='2', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=709.0, output_tokens=None, search_units=None, classifications=None, image_tokens=0), tokens=None, warnings=None) inputs=[{'content': [{'type': 'text', 'text': \"page_content='7 \\nZintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \\n \\nLaravel Breeze  domyślnie generuje strony za pomocą wi doków Blade, ale m ożna \\nskonfigurować go do wykorzystania widoków wykorzystujących Vue, React lub Inertia. \\nNajprostsza konfiguracja korzysta z domyślego silnika widoków Blade.  Ten silnik oraz \\nBreeze wskazaliśmy przy tworzeniu nowego projektu. \\n \\nAby poprawnie działało uwierzytelnienie użytkownika, należy wykorzystać (utworzone już \\nw tym celu przez Laravel) elementy związane z zapisem danych użytkownika w bazie danych \\n(domyślnie MySQL) . W celu ustawienia połączenia do bazy danych, w pliku .env \\n(w głównym folderze projektu) należy podać dane autoryzujące dostęp do bazy danych. Dla \\nMySQL domyślne ustawienia w pliku .env (DB_CONNECTION, DB_HOST, itd.) są już \\ngotowe (Rys. 12.8). \\n \\n \\nRys. 12.8. Domyślne ustawienia połączenia do bazy o nazwie lab12 na serwerze MySQL \\nKorzystając z narzędzia phpMyAdmin utwórz nową bazę danych o nazwie lab12 (taka nazwa \\nbazy podana jest jako domyślna w ustawieniu DB_DATABASE=lab12 (Rys. 12.8). \\nDo pracy z bazą danych wykorzystamy tzw. migracje. Migracje to pliki wykonuj ące \\nokreślone operacje na bazie danych, takie jak np. tworzenie tabel.  \\nPliki migracji  znajdują się w katalogu database/migrations. Laravel zadbał już o to, by \\nutworzyć odpowiedni plik migracji dla tabeli użytkowników  users. Gotowe pliki migracji \\nmożna podejrzeć w projekcie ( Rys. 12.9). Migracja z Rys. 12.9 tworzy tabelę users. Nazwy \\ni typy pól tabeli (kolumn) zdefiniowano bezpośrednio z poziomu kodu w metodzie up() klasy \\no nazwie CreateUserTable, która dziedziczy po klasie Migration.' metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 6, 'page_label': '7'}\"}]}] response_type='embeddings_by_type'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:32:28.792713Z",
     "start_time": "2025-07-14T16:32:26.021688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a doctor, explain things thoroughly, try to analyze which illness could the patient suffer from. and what's the best solution to resolve it.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Teach me how to learn quicker\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "print(\"Given 3 choices with higher randomness: \\n\")\n",
    "num_choices = 3\n",
    "#for i in range(num_choices):\n",
    " #   print(chat_completion.choices[i].message.content)\n",
    "\n",
    "# Print the completion returned by the LLM.\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "id": "f0d56867bab16465",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 3 choices with higher randomness: \n",
      "\n",
      "Learning is a complex process that involves multiple cognitive, emotional, and environmental factors. To help you learn quicker, I'll provide you with a comprehensive approach that incorporates various strategies, techniques, and tips.\n",
      "\n",
      "**Understanding How We Learn**\n",
      "\n",
      "Before we dive into the strategies, let's briefly discuss how our brains process information. The human brain has an incredible ability to reorganize and adapt throughout life, a concept known as neuroplasticity. When we learn, our brains create new connections between neurons, which can be strengthened or weakened based on the frequency and quality of use.\n",
      "\n",
      "**Effective Learning Strategies**\n",
      "\n",
      "1. **Setting Clear Goals**: Establishing specific, measurable, achievable, relevant, and time-bound (SMART) goals helps you focus on what you want to learn. Break down larger goals into smaller, manageable chunks, and prioritize them based on importance and urgency.\n",
      "2. **Active Recall**: This involves actively recalling information from memory rather than simply re-reading it. Try recalling key concepts, formulas, or procedures without looking at your notes or other resources.\n",
      "3. **Spaced Repetition**: Review material at increasingly longer intervals to help solidify it in your long-term memory. This technique can be applied using flashcards, apps, or by creating a schedule for reviewing notes.\n",
      "4. **Chunking**: Organize information into smaller, more manageable chunks, such as breaking down a large text into headings, subheadings, and bullet points.\n",
      "5. **Mnemonics**: Use associations, acronyms, or rhymes to help encode information in a more memorable way.\n",
      "6. **Multisensory Learning**: Combine different senses, such as visual, auditory, and kinesthetic, to learn new information. For example, watching a video, listening to a podcast, and taking notes can be more effective than just reading text.\n",
      "7. **Practice Active Learning**: Engage with the material by asking questions, discussing it with others, or summarizing it in your own words.\n",
      "8. **Get Enough Sleep**: Sleep plays an essential role in memory consolidation, so ensure you get sufficient rest to help your brain process and retain new information.\n",
      "9. **Stay Organized**: Keep all your study materials, including notes, schedules, and goals, organized and easily accessible.\n",
      "10. **Use Technology Strategically**: Utilize digital tools, such as apps, browser extensions, and online resources, to streamline your learning process, stay focused, and access relevant information.\n",
      "\n",
      "**Additional Tips to Enhance Learning**\n",
      "\n",
      "* **Minimize Distractions**: Identify potential distractions, such as social media, email, or phone notifications, and eliminate them while you study.\n",
      "* **Take Regular Breaks**: Use the Pomodoro Technique, which involves working in focused 25-minute increments, followed by a 5-minute break.\n",
      "* **Stay Hydrated and Energized**: Drink plenty of water and maintain a healthy diet to support your brain function and overall well-being.\n",
      "* **Seek Help When Needed**: Don't hesitate to ask for help from teachers, classmates, or mentors if you're struggling with a particular concept or subject.\n",
      "* **Review and Reflect**: Regularly review what you've learned and reflect on what works best for you. Adjust your strategies as needed to optimize your learning process.\n",
      "\n",
      "**Neuroscience-Based Learning Techniques**\n",
      "\n",
      "1. **Brainwave Entrainment**: Listen to music or soundscapes that stimulate alpha, beta, or theta brainwaves, which can help improve focus, relaxation, or creativity.\n",
      "2. **Mindfulness Meditation**: Practice mindfulness meditation to enhance attention, working memory, and emotional regulation.\n",
      "3. **Neuro-Linguistic Programming (NLP)**: Use NLP techniques, such as visualization, affirmations, or self-talk, to rewire your brain and build confidence.\n",
      "\n",
      "**Implementation and Accountability**\n",
      "\n",
      "1. **Create a Learning Schedule**: Plan out your study sessions, breaks, and review periods to stay on track and maintain consistency.\n",
      "2. **Track Progress**: Use a journal, spreadsheet, or app to monitor your progress, identify areas for improvement, and adjust your strategies accordingly.\n",
      "3. **Find a Study Buddy or Accountability Partner**: Share your goals and progress with a friend or mentor to gain support, motivation, and constructive feedback.\n",
      "\n",
      "By incorporating these strategies, techniques, and tips into your daily routine, you'll be able to learn more efficiently and effectively. Remember to stay patient, persistent, and open to new experiences, and you'll be well on your way to developing a lifelong love of learning.\n",
      "\n",
      "As a doctor, I would like to emphasize the importance of taking care of your physical and mental well-being while learning. Ensure you're getting enough sleep, exercise, and nutrition to support your overall health, and don't hesitate to seek help if you're experiencing any signs of burnout or stress.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T16:32:29.288524Z",
     "start_time": "2025-07-14T16:32:29.283832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "urls = [\n",
    "    \"https://www.matthewlozinski.com/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=co,\n",
    ")\n",
    "\n",
    "vectorstore_retriever = vectorstore.as_retriever()\n",
    "\"\"\""
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.vectorstores import FAISS\\n\\nurls = [\\n    \"https://www.matthewlozinski.com/\",\\n]\\n\\ndocs = [WebBaseLoader(url).load() for url in urls]\\ndocs_list = [item for sublist in docs for item in sublist]\\n\\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\\n    chunk_size=512, chunk_overlap=0\\n)\\ndoc_splits = text_splitter.split_documents(docs_list)\\n\\nvectorstore = FAISS.from_documents(\\n    documents=doc_splits,\\n    embedding=co,\\n)\\n\\nvectorstore_retriever = vectorstore.as_retriever()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:32:29.755233Z",
     "start_time": "2025-07-14T16:32:29.338414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Path to shared documents inside the container\n",
    "documents_path = \"/app/shared_documents/user_1\"\n",
    "\n",
    "# List files\n",
    "files = os.listdir(documents_path)\n",
    "\n",
    "# Print the list of files\n",
    "print(files)"
   ],
   "id": "1dd56887ed17044f",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/app/shared_documents/user_1'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m documents_path = \u001B[33m\"\u001B[39m\u001B[33m/app/shared_documents/user_1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# List files\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m files = os.listdir(documents_path)\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Print the list of files\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(files)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '/app/shared_documents/user_1'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:33:01.383020Z",
     "start_time": "2025-07-14T16:33:01.380375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    pass\n",
    "    #messages: Annotated[list, add_messages]"
   ],
   "id": "b155f83d403cdf2f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:50:51.660484Z",
     "start_time": "2025-07-16T05:50:48.350567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "\n",
    "embeddings = CohereEmbeddings(model=\"embed-v4.0\")\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(), # It is in RAM, thus in future I will need to store it in Postgres container's volume\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "documents = [doc for doc in docs if doc is not None]\n",
    "ids = [f\"{i}\" for i in range(1, len(docs) + 1, 1)]\n",
    "vector_store.add_documents(documents=documents, ids=ids)"
   ],
   "id": "61268017a194a1e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T15:07:06.476582Z",
     "start_time": "2025-07-16T15:07:06.472701Z"
    }
   },
   "cell_type": "code",
   "source": "type(vector_store)",
   "id": "977d99510f31427d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.faiss.FAISS"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:51:14.044314Z",
     "start_time": "2025-07-16T05:51:14.041022Z"
    }
   },
   "cell_type": "code",
   "source": "type(vector_store)",
   "id": "481237087c2932a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.faiss.FAISS"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:57:21.797236Z",
     "start_time": "2025-07-16T05:57:21.339996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for dev testing on embeddings accuracy\n",
    "results = vector_store.similarity_search_with_score(query=\"phpmyadmin wraz z mongo czy top mozliwe\",k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
   ],
   "id": "c72ac7674d73d647",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=1.412498] 13 \n",
      "Zintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \n",
      " \n",
      " \n",
      "Rys. 12.18. Wykonanie migracji \n",
      " \n",
      "Sprawdź w PhpMyAdmin efekt wykonania polecenia  z Rys. 12.1 8. Następnie utwórz klasę \n",
      "modelu Comment (zwróć uwagę na liczbę pojedynczą w  nazwie modelu ), który będzie \n",
      "abstrakcyjną reprezentacją bytu bazodanowego dla tabeli komentarzy z  poziomu aplikacji  \n",
      "(Rys. 12.19): \n",
      "php artisan make:model Comment \n",
      " \n",
      " \n",
      "Rys. 12.19. Polecenie tworzenia modelu \n",
      " \n",
      "W wyniku wykonania polecenia  z Rys. 12. 19, w katalogu app/Models utworzył się plik \n",
      "Comment.php z definicją klasy Comment. Dodaj do niego fragment ( Rys. 12.20) definiujący \n",
      "relację jeden do jednego (jeden komentarz ma jednego autora).  \n",
      "Dodaj także import klasy User. [{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13'}]\n",
      "* [SIM=1.444043] 8 \n",
      "Zintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \n",
      " \n",
      " \n",
      "Rys. 12.9. Gotowa klasa migracji dla tabeli users (plik \n",
      "2014_10_12_000000_create_users_table.php \n",
      "W celu fizycznego utworzenia tabeli users i innych zdefiniowanych tam tabel w naszej bazie \n",
      "danych lab12, w ystarczy już tylko wywołać komendę migracji z poziomu wiersza poleceń  \n",
      "(Rys. 12.10): \n",
      "php artisan migrate \n",
      " \n",
      "Rys. 12.10. Wynik działania polecenia migracji [{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 7, 'page_label': '8'}]\n",
      "* [SIM=1.454236] composer global require laravel/installer \n",
      "UWAGA! W salach laboratoryjnych w systemie Windows jest zainstalowany Composer, ale \n",
      "skonfigurowany do pracy z php zainstalowanym w katalogu C:/tools/php81. Aby wszystko  \n",
      "działało poprawnie trzeba zmodyfikować ustawienia w pliku php.ini z katalogu \n",
      "C:/tools/php81 (NIE Z XAMPP!!!). W tym celu należy: \n",
      " odkomentować ustawienie: extension = fileinfo \n",
      " odkomentować ustawienie: extension = pdo_mysql \n",
      " odkomentować i ustawić bezwzględną ścieżkę do katalogu, w którym znajdują się \n",
      "dodatkowe moduły: extension_dir = \"c:/tools/php81/ext\" [{'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1'}]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:56:51.632988Z",
     "start_time": "2025-07-16T05:56:51.630265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for doc, score in results:\n",
    "    print(type(doc.metadata))\n",
    "    print(type(doc.page_content))"
   ],
   "id": "c95549117998e257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41bfcd93ad715dab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:57:27.408304Z",
     "start_time": "2025-07-16T05:57:27.149730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reranking the documents based on best document's embeddings\n",
    "co_rerank = cohere.ClientV2()\n",
    "\n",
    "docs = [doc.page_content + \" \" + str(doc.metadata) for doc, score in results]\n",
    "\n",
    "response = co_rerank.rerank(\n",
    "    model=\"rerank-v3.5\",\n",
    "    query=\"What is the capital of the United States?\",\n",
    "    documents=docs,\n",
    "    top_n=3,\n",
    ")\n",
    "print(response)\n"
   ],
   "id": "8c30d56894532f67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='25aa065e-62cb-496e-96af-302d2b0b8fec' results=[V2RerankResponseResultsItem(document=None, index=1, relevance_score=0.044039294), V2RerankResponseResultsItem(document=None, index=0, relevance_score=0.03733048), V2RerankResponseResultsItem(document=None, index=2, relevance_score=0.036291793)] meta=ApiMeta(api_version=ApiMetaApiVersion(version='2', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=None, output_tokens=None, search_units=1.0, classifications=None), tokens=None, warnings=None)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:33:02.819603815Z",
     "start_time": "2025-07-13T19:40:07.814934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_message = \"Jak mam używać PhpMyadmina z mongodb, czy to wgl mozliwe?\"\n",
    "results = vector_store.similarity_search(query=f\"{user_message}\",k=1)"
   ],
   "id": "ad55efd576c0b5a4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T16:33:02.820279179Z",
     "start_time": "2025-07-13T19:40:19.546Z"
    }
   },
   "cell_type": "code",
   "source": "print(results)",
   "id": "347b20de5d70384d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='14', metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13'}, page_content='13 \\nZintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \\n \\n \\nRys. 12.18. Wykonanie migracji \\n \\nSprawdź w PhpMyAdmin efekt wykonania polecenia  z Rys. 12.1 8. Następnie utwórz klasę \\nmodelu Comment (zwróć uwagę na liczbę pojedynczą w  nazwie modelu ), który będzie \\nabstrakcyjną reprezentacją bytu bazodanowego dla tabeli komentarzy z  poziomu aplikacji  \\n(Rys. 12.19): \\nphp artisan make:model Comment \\n \\n \\nRys. 12.19. Polecenie tworzenia modelu \\n \\nW wyniku wykonania polecenia  z Rys. 12. 19, w katalogu app/Models utworzył się plik \\nComment.php z definicją klasy Comment. Dodaj do niego fragment ( Rys. 12.20) definiujący \\nrelację jeden do jednego (jeden komentarz ma jednego autora).  \\nDodaj także import klasy User.')]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T05:59:35.247607Z",
     "start_time": "2025-07-16T05:59:34.355516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\", # Maybe with threshold, but I would have to monitor and investigate it in the production.\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "retriever.invoke(\"Jak mam używać PhpMyadmina z mongodb, czy to wgl mozliwe?\")"
   ],
   "id": "bf15972074de9f00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='14', metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 12, 'page_label': '13'}, page_content='13 \\nZintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \\n \\n \\nRys. 12.18. Wykonanie migracji \\n \\nSprawdź w PhpMyAdmin efekt wykonania polecenia  z Rys. 12.1 8. Następnie utwórz klasę \\nmodelu Comment (zwróć uwagę na liczbę pojedynczą w  nazwie modelu ), który będzie \\nabstrakcyjną reprezentacją bytu bazodanowego dla tabeli komentarzy z  poziomu aplikacji  \\n(Rys. 12.19): \\nphp artisan make:model Comment \\n \\n \\nRys. 12.19. Polecenie tworzenia modelu \\n \\nW wyniku wykonania polecenia  z Rys. 12. 19, w katalogu app/Models utworzył się plik \\nComment.php z definicją klasy Comment. Dodaj do niego fragment ( Rys. 12.20) definiujący \\nrelację jeden do jednego (jeden komentarz ma jednego autora).  \\nDodaj także import klasy User.'),\n",
       " Document(id='10', metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 8, 'page_label': '9'}, page_content='9 \\nZintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \\n \\nSprawdź w phpMyAdmin jakie tabele zostały utworzone po uruchomieniu migracji. Uruchom \\nw przeglądarce stronę startową i z arejestruj (korzystając z przycisku Register na stronie \\ngłównej) nowego użytkownika , sprawdź efekt logowania  i przetestuj możliwość edycji \\nprofilu. Przejrzyj jakie rekordy zostały dodane do tabeli users i migrations. Na koniec \\nwyloguj użytkownika.  \\n4.  Widoki dla komentarzy \\nKolejny etap to utworzeni e widoków. W klasycznym wzorcu MVC, nazwy w idoków są \\nzwracane jako wynik działania metody (akcji) kontrolera. W  przykładzie utworzymy stronę \\nwidoku z formularzem do wprowadzenia komentarza do księgi gości. \\nZadanie podzielimy na dwa etapy: \\na) utworzenie widoku dla księgi gości, \\nb) utworzenie logiki dodawania komentarzy przez użytkowników. \\n \\nOtwórz plik kontrolera CommentsController, i zmodyfikuj jego metodę index() która \\nzwracała prosty napis „Hello Laravel”. Teraz zmienimy to tak, aby zwracany był specjalny \\nwidok za pomocą funkcji  view(). W tym celu zmień instrukcję return w metodzie index() \\nkontrolera CommentController jak pokazano na Rys. 12.11. \\n \\nRys. 12.11. Modyfikacja metody index() kontrolera CommentsController \\nNastępnie, w katalogu resources/views utwórz plik widoku comments.blade.php z treścią jak \\nw załączonym do paczki z ćwiczeniem pliku. W  Laravel widoki (dokumenty o  strukturze \\nHTML) są domyślnie obsługiwane przez silnik Blade. Finalna postać pliku będzie korzystała \\nz silnika Blade do generowani a dynamicznie zawartości na podstawie danych przesłanych \\nz metod kontrolera. Na razie pokażemy statyczną zawartość komentarza testowego.  \\nPonownie uruchom widok dla komentarzy ‘comments’ w przeglądarce (Rys. 12.12).'),\n",
       " Document(id='19', metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2024-11-29T21:25:14+01:00', 'author': 'Marcel', 'moddate': '2024-11-29T21:25:14+01:00', 'source': '/home/matthew/Desktop/med-assistant-project/backend/media/documents/user_1/Lab0_Laravel11.pdf', 'total_pages': 30, 'page': 17, 'page_label': '18'}, page_content='18 \\nZintegrowany Program Rozwoju Politechniki Lubelskiej – część druga \\n \\n \\nRys. 12.27. Zapis komentarza w metodzie store() kontrolera CommentsController \\nPrzetestuj działanie metody store() - za pomocą formularza dodawania, wprowadź nowy \\nkomentarz i sprawdź w PhpMyAdmin, czy został on prawidłowo dodany do tabeli comments. \\nOstatni etap to wyświetlenie wszystkich komentarzy pobranych z  bazy danych. W tym celu  \\nw metodzie index() kontrolera CommentController zmodyfikuj kod jak na Rys. 12.2 8. \\nWykorzystano tu klasę modelu Comment, która po stronie aplikacji reprezentuje obiekt \\nkomentarza odpowiadający pojedynczemu rekordowi tabeli comments w bazie danych . \\nZmienna $comments jest rezultatem zapytania wykonanego za pomocą metody get() \\nnarzędzia Eloquent i zawiera tablicę obiektów klasy Comment, która reprezentuje wszystkie, \\nposortowane alfabetycznie, rekordy tabeli comments. Ta tablica zostaje prz ekazana do \\nwidoku, który wyświetli wszystkie komentarze z tabeli na stronie (Rys. 12.28).')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ],
   "id": "972b73d0c514a24a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T09:07:00.545667Z",
     "start_time": "2025-07-16T09:07:00.230063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_rewriter = ChatGroq(temperature=0.01, model=\"llama-3.1-8b-instant\")\n",
    "llm_answerer = ChatGroq(temperature=0.5, model=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "human_message = \"So, I was wondering, like, what’s the actual difference between PostgreSQL and phpMyAdmin? Because I know both are kind of related to databases, right? But I’m not really sure if one of them is the database itself and the other is just a tool or something to look at the data, or maybe they both do the same thing in different ways? Also, can you use phpMyAdmin with PostgreSQL, or is it only for something like MySQL? I feel a bit confused because people talk about them like they’re both important, but I don’t know how they work together or if they even do.\"\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that rewrites verbose user questions into short, keyword-rich queries suitable for vector similarity search. Do not answer the question. Only return the rewritten query.\\n\\nExample:\\nInput: 'Can you explain what the difference is between SQL and NoSQL databases and when to use them?'\\nOutput: 'difference SQL vs NoSQL databases usage scenario'\\n\",\n",
    "    ),\n",
    "    (\"human\", f\"{human_message}\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm_rewriter.invoke(messages)\n",
    "ai_msg"
   ],
   "id": "59f9836f537fe03d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='PostgreSQL vs phpMyAdmin difference database tool relationship', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 232, 'total_tokens': 243, 'completion_time': 0.03058522, 'prompt_time': 0.013696378, 'queue_time': 0.038573243, 'total_time': 0.044281598}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_348199b5a7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--49eac85d-5fe6-4236-b88c-d3e9c0ffbc63-0', usage_metadata={'input_tokens': 232, 'output_tokens': 11, 'total_tokens': 243})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "rag = StateGraph(State)\n",
    "rag.add_node(\"rewriter\", rewriter)\n",
    "rag.add_node(\"answerer\", answerer)\n",
    "rag.add_node(\"router\", router)\n",
    "rag.add_node(\"scrape_webpages\", scrape_webpages)\n",
    "rag.add_edge(scrape_webpages, END)\n",
    "\n",
    "rag.add_edge(START, \"supervisor\")\n",
    "rag = rag.compile()"
   ],
   "id": "f1750de34daf61b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import langchain_community\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm_rewriter = ChatGroq(temperature=0.01, model=\"llama-3.1-8b-instant\")\n",
    "llm_answerer = ChatGroq(temperature=0.5, model=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "# Define the state with message history\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    rewritten_query: str\n",
    "    retrieved_docs: List[str]\n",
    "    reflection_count: int\n",
    "    router_decision: str\n",
    "\n",
    "# Node functions\n",
    "def rewriter(state: State) -> State:\n",
    "    \"\"\"Rewrite user message to be keyword-friendly for vector search\"\"\"\n",
    "    # Get the last user message\n",
    "    human_message = state[\"messages\"][-1][\"content\"]\n",
    "\n",
    "    messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that rewrites verbose user questions into short, keyword-rich queries suitable for vector similarity search. Do not answer the question. Only return the rewritten query.\\n\\nExample:\\nInput: 'Can you explain what the difference is between SQL and NoSQL databases and when to use them?'\\nOutput: 'difference SQL vs NoSQL databases usage scenario'\\n\",\n",
    "    ),\n",
    "    (\"human\", f\"{human_message}\"),\n",
    "    ]\n",
    "\n",
    "        # Your LLM call to rewrite the query\n",
    "    rewritten = llm_rewriter.invoke(messages)\n",
    "    rewritten_placeholder = f\"keywords: {human_message}\"  # Placeholder\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": f\"Query rewritten to: {rewritten}\"}],\n",
    "        \"rewritten_query\": rewritten\n",
    "    }\n",
    "\n",
    "def retriever(state: State, vector_store: langchain_community.vectorstores.faiss.FAISS) -> State:\n",
    "    \"\"\"Retrieve documents based on rewritten query\"\"\"\n",
    "    # Your retrieval logic here\n",
    "\n",
    "    query = state[\"rewritten_query\"]\n",
    "\n",
    "    results = vector_store.similarity_search_with_score(query=query, k=3)\n",
    "\n",
    "    co_rerank = cohere.ClientV2()\n",
    "\n",
    "    docs = [doc.page_content + \" \" + str(doc.metadata) for doc, score in results]\n",
    "\n",
    "    response = co_rerank.rerank(\n",
    "        model=\"rerank-v3.5\",\n",
    "        query=query,\n",
    "        documents=docs,\n",
    "        top_n=3,\n",
    "    )\n",
    "\n",
    "    reranked_docs = [docs[result.index] for result in response.results]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": f\"Retrieved {len(reranked_docs)} documents\"}],\n",
    "        \"retrieved_docs\": reranked_docs\n",
    "    }\n",
    "\n",
    "def router(state: State) -> State:\n",
    "    \"\"\"Decide whether to scrape web, self-reflect, or respond to user\"\"\"\n",
    "    # Your LLM call to make routing decision\n",
    "    # Consider: retrieved docs quality, reflection count, etc.\n",
    "\n",
    "    reflection_count = state.get(\"reflection_count\", 0)\n",
    "\n",
    "    # Simple logic - you can replace with LLM decision\n",
    "    if reflection_count >= 3:\n",
    "        decision = \"respond_to_user\"\n",
    "    elif not state[\"retrieved_docs\"] or len(state[\"retrieved_docs\"]) < 2:\n",
    "        decision = \"scrape_webpages\"\n",
    "    elif reflection_count < 2:\n",
    "        decision = \"self_reflect\"\n",
    "    else:\n",
    "        decision = \"respond_to_user\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": f\"Router decision: {decision}\"}],\n",
    "        \"router_decision\": decision\n",
    "    }\n",
    "\n",
    "def scrape_webpages(state: State) -> State:\n",
    "    \"\"\"Scrape web pages for additional information\"\"\"\n",
    "    # Your web scraping logic here\n",
    "    scraped_content = f\"Scraped content related to {state['rewritten_query']}\"\n",
    "\n",
    "    # Add scraped content to retrieved docs\n",
    "    updated_docs = state[\"retrieved_docs\"] + [scraped_content]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"Web scraping completed\"}],\n",
    "        \"retrieved_docs\": updated_docs\n",
    "    }\n",
    "\n",
    "def self_reflect(state: State) -> State:\n",
    "    \"\"\"Self-reflect on the current information and decide next steps\"\"\"\n",
    "    reflection_count = state.get(\"reflection_count\", 0) + 1\n",
    "\n",
    "    # Your LLM call for self-reflection\n",
    "    # reflection = llm.invoke(f\"Reflect on this information: {state['retrieved_docs']}\")\n",
    "    reflection = f\"Reflection {reflection_count}: Need more specific information\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": reflection}],\n",
    "        \"reflection_count\": reflection_count\n",
    "    }\n",
    "\n",
    "def answerer(state: State) -> State:\n",
    "    \"\"\"Generate final response to user\"\"\"\n",
    "    # Your LLM call to generate final answer\n",
    "    # answer = llm.invoke(f\"Answer based on: {state['retrieved_docs']}\")\n",
    "    answer = f\"Here's your answer based on the retrieved information: {state['retrieved_docs']}\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": answer}]\n",
    "    }\n",
    "\n",
    "# Conditional edge function\n",
    "def route_decision(state: State) -> Literal[\"scrape_webpages\", \"self_reflect\", \"answerer\"]:\n",
    "    \"\"\"Route based on the router's decision\"\"\"\n",
    "    decision = state.get(\"router_decision\", \"answerer\")\n",
    "\n",
    "    if decision == \"scrape_webpages\":\n",
    "        return \"scrape_webpages\"\n",
    "    elif decision == \"self_reflect\":\n",
    "        return \"self_reflect\"\n",
    "    else:\n",
    "        return \"answerer\"\n",
    "\n",
    "# Create the graph\n",
    "def create_rag_graph():\n",
    "    rag = StateGraph(State)\n",
    "\n",
    "    # Add nodes\n",
    "    rag.add_node(\"rewriter\", rewriter)\n",
    "    rag.add_node(\"retriever\", retriever)\n",
    "    rag.add_node(\"router\", router)\n",
    "    rag.add_node(\"scrape_webpages\", scrape_webpages)\n",
    "    rag.add_node(\"self_reflect\", self_reflect)\n",
    "    rag.add_node(\"answerer\", answerer)\n",
    "\n",
    "    # Add edges\n",
    "    rag.add_edge(START, \"rewriter\")\n",
    "    rag.add_edge(\"rewriter\", \"retriever\")\n",
    "    rag.add_edge(\"retriever\", \"router\")\n",
    "\n",
    "    # Conditional edges from router\n",
    "    rag.add_conditional_edges(\n",
    "        \"router\",\n",
    "        route_decision,\n",
    "        {\n",
    "            \"scrape_webpages\": \"scrape_webpages\",\n",
    "            \"self_reflect\": \"self_reflect\",\n",
    "            \"answerer\": \"answerer\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # After scraping, go back to router\n",
    "    rag.add_edge(\"scrape_webpages\", \"router\")\n",
    "\n",
    "    # After self-reflection, go back to router\n",
    "    rag.add_edge(\"self_reflect\", \"router\")\n",
    "\n",
    "    # End after answering\n",
    "    rag.add_edge(\"answerer\", END)\n",
    "\n",
    "    return rag.compile()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the compiled graph\n",
    "    rag_graph = create_rag_graph()\n",
    "\n",
    "    # Example usage\n",
    "    initial_state = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What is machine learning?\"}],\n",
    "        \"rewritten_query\": \"\",\n",
    "        \"retrieved_docs\": [],\n",
    "        \"reflection_count\": 0,\n",
    "        \"router_decision\": \"\"\n",
    "    }\n",
    "\n",
    "    # Run the graph\n",
    "    final_state = rag_graph.invoke(initial_state)\n",
    "    print(\"Final messages:\", final_state[\"messages\"])"
   ],
   "id": "44367c22e6d567f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.tools import tool, node, branch\n",
    "from langgraph.prebuilt.tool_router import ToolRouter, ToolDescription\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import requests\n",
    "import asyncio\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: GraphState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"chat\", chatbot)\n",
    "graph.add_edge(START, \"chat\")\n",
    "\n",
    "#######################\n",
    "# STEP 1: DEFINE TOOL #\n",
    "#######################\n",
    "\n",
    "# Here we define a simple tool using the `@tool` decorator\n",
    "@tool\n",
    "def joke_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool that fetches a random joke from the JokeAPI.\n",
    "    You can ask for a joke by calling this tool.\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://official-joke-api.appspot.com/jokes/random\")\n",
    "    if response.status_code == 200:\n",
    "        joke_data = response.json()\n",
    "        return f\"{joke_data['setup']} ... {joke_data['punchline']}\"\n",
    "    else:\n",
    "        return \"Failed to fetch a joke, try again later.\"\n",
    "\n",
    "#################################\n",
    "# STEP 2: SET UP TOOL ROUTER    #\n",
    "#################################\n",
    "\n",
    "# We create a tool router which decides when to call the tool\n",
    "# Based on the descriptions, the LLM will learn which tool to call\n",
    "tool_router = ToolRouter(\n",
    "    tools=[\n",
    "        ToolDescription(\n",
    "            name=\"joke_tool\",\n",
    "            description=\"Useful when user asks for a joke or something funny.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "###############################\n",
    "# STEP 3: ROUTER NODE LOGIC   #\n",
    "###############################\n",
    "\n",
    "# The main router node uses the LLM to choose between tools or regular reply\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "@node\n",
    "async def router(state: GraphState):\n",
    "    user_input = state[\"user_input\"]\n",
    "\n",
    "    # Use the tool router to decide if we should call a tool\n",
    "    routing_decision = await tool_router.invoke(user_input)\n",
    "\n",
    "    if routing_decision.tool_calls:\n",
    "        # The tool router wants to use a tool\n",
    "        selected_tool = routing_decision.tool_calls[0][\"name\"]\n",
    "        tool_args = routing_decision.tool_calls[0][\"args\"][\"query\"]\n",
    "        print(f\"Router decision: calling tool {selected_tool} with query {tool_args}\")\n",
    "        return {\"next\": selected_tool, \"tool_args\": tool_args}\n",
    "    else:\n",
    "        # Otherwise, fallback to normal assistant\n",
    "        print(\"Router decision: fallback to normal assistant.\")\n",
    "        return {\"next\": \"assistant\"}\n",
    "\n",
    "##############################\n",
    "# STEP 4: ASSISTANT NODE     #\n",
    "##############################\n",
    "\n",
    "@node\n",
    "async def assistant(state: GraphState):\n",
    "    user_input = state[\"user_input\"]\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Basic LLM chat completion\n",
    "    response = await llm.ainvoke([{\"role\": \"user\", \"content\": user_input}])\n",
    "    messages.append(response.content)\n",
    "    return {\"messages\": messages, \"user_input\": user_input}\n",
    "\n",
    "#################################\n",
    "# STEP 5: TOOL NODE WRAPPING   #\n",
    "#################################\n",
    "\n",
    "# Wrap the tool function with ToolNode so it can be part of LangGraph\n",
    "joke_tool_node = ToolNode(joke_tool)\n",
    "\n",
    "@node\n",
    "async def joke_tool_handler(state: GraphState, tool_args: Annotated[str, \"tool_args\"]):\n",
    "    result = await joke_tool_node.ainvoke(tool_args)\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(f\"Joke: {result}\")\n",
    "    return {\"messages\": messages, \"user_input\": state[\"user_input\"]}\n",
    "\n",
    "##############################\n",
    "# STEP 6: BUILD THE GRAPH    #\n",
    "##############################\n",
    "\n",
    "graph_builder = StateGraph(GraphState)\n",
    "\n",
    "# Start from router\n",
    "graph_builder.add_node(\"router\", router)\n",
    "graph_builder.add_node(\"assistant\", assistant)\n",
    "graph_builder.add_node(\"joke_tool\", joke_tool_handler)\n",
    "\n",
    "# Edges:\n",
    "graph_builder.set_entry_point(\"router\")\n",
    "\n",
    "# Conditional routing: router decides where to go next\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda x: x[\"next\"],  # The `next` value decides routing\n",
    "    {\n",
    "        \"assistant\": \"assistant\",\n",
    "        \"joke_tool\": \"joke_tool\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After assistant or joke_tool, go back to router (loop)\n",
    "graph_builder.add_edge(\"assistant\", \"router\")\n",
    "graph_builder.add_edge(\"joke_tool\", \"router\")\n",
    "\n",
    "# Finalize\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "##############################################\n",
    "# STEP 7: TESTING THE FLOW                   #\n",
    "##############################################\n",
    "\n",
    "async def run_example():\n",
    "    state = {\"user_input\": \"Tell me a joke!\", \"messages\": []}\n",
    "\n",
    "    # Run a few steps in the loop\n",
    "    for step in range(3):\n",
    "        state = await graph.ainvoke(state)\n",
    "        print(f\"\\n--- Step {step+1} Output ---\")\n",
    "        for message in state[\"messages\"]:\n",
    "            print(message)\n",
    "        # Break loop if already satisfied\n",
    "        if len(state[\"messages\"]) > 0 and \"Joke:\" in state[\"messages\"][-1]:\n",
    "            break\n",
    "        state[\"user_input\"] = \"Thanks!\"\n",
    "\n",
    "asyncio.run(run_example())\n"
   ],
   "id": "a00bc3ec01b040fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "3040bde5bcf2d9f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "def groq_llm(prompt: str, system_prompt: str = \"\") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3-3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ],
   "id": "31a296e153979634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.graphs import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1. LLMs\n",
    "llm = ChatOpenAI(model=\"gpt-4\")  # Or any you use\n",
    "\n",
    "# 2. Prompt to transform user query into a search-friendly keyword version\n",
    "transform_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Transform the following question into a concise keyword-based search query:\\n\\n{question}\"\n",
    ")\n",
    "transform_chain = LLMChain(llm=llm, prompt=transform_prompt)\n",
    "\n",
    "# 3. Retriever: assume it's already set up\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# 4. Final answer prompt: uses documents + original question\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Given the user's question and these documents:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the question: {question}\n",
    "\"\"\"\n",
    ")\n",
    "answer_chain = LLMChain(llm=llm, prompt=answer_prompt)\n",
    "\n",
    "# ---- Graph functions ----\n",
    "\n",
    "# Node: transforms user input into keyword query\n",
    "def transform_node(state):\n",
    "    question = state[\"question\"]\n",
    "    keyword_query = transform_chain.run({\"question\": question})\n",
    "    return {\"question\": question, \"keyword_query\": keyword_query}\n",
    "\n",
    "# Node: runs vector search\n",
    "def retrieve_node(state):\n",
    "    keyword_query = state[\"keyword_query\"]\n",
    "    docs = retriever.get_relevant_documents(keyword_query)\n",
    "    return {\"question\": state[\"question\"], \"context\": \"\\n\\n\".join(doc.page_content for doc in docs)}\n",
    "\n",
    "# Node: generates final output\n",
    "def answer_node(state):\n",
    "    result = answer_chain.run({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    return {\"answer\": result}\n",
    "\n",
    "# ---- Build the graph ----\n",
    "graph = StateGraph()\n",
    "\n",
    "graph.add_node(\"Transform\", RunnableLambda(transform_node))\n",
    "graph.add_node(\"Retrieve\", RunnableLambda(retrieve_node))\n",
    "graph.add_node(\"Answer\", RunnableLambda(answer_node))\n",
    "\n",
    "graph.set_entry_point(\"Transform\")\n",
    "graph.add_edge(\"Transform\", \"Retrieve\")\n",
    "graph.add_edge(\"Retrieve\", \"Answer\")\n",
    "graph.set_finish_point(\"Answer\")\n",
    "\n",
    "runnable_graph = graph.compile()\n"
   ],
   "id": "df475cf457b1fd74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, node, tool, branch\n",
    "from langgraph.prebuilt.tool_router import ToolRouter, ToolDescription\n",
    "from typing import TypedDict, Annotated\n",
    "import requests\n",
    "\n",
    "# Define a basic state which holds the current user input and messages\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: list\n",
    "\n",
    "#######################\n",
    "# STEP 1: DEFINE TOOL #\n",
    "#######################\n",
    "\n",
    "# Here we define a simple tool using the `@tool` decorator\n",
    "@tool\n",
    "def joke_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool that fetches a random joke from the JokeAPI.\n",
    "    You can ask for a joke by calling this tool.\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://official-joke-api.appspot.com/jokes/random\")\n",
    "    if response.status_code == 200:\n",
    "        joke_data = response.json()\n",
    "        return f\"{joke_data['setup']} ... {joke_data['punchline']}\"\n",
    "    else:\n",
    "        return \"Failed to fetch a joke, try again later.\"\n",
    "\n",
    "#################################\n",
    "# STEP 2: SET UP TOOL ROUTER    #\n",
    "#################################\n",
    "\n",
    "tools = [\n",
    "        ToolDescription(\n",
    "            name=\"joke_tool\",\n",
    "            description=\"Useful when user asks for a joke or something funny.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# We create a tool router which decides when to call the tool\n",
    "# Based on the descriptions, the LLM will learn which tool to call\n",
    "tool_router = ToolRouter(\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "###############################\n",
    "# STEP 3: ROUTER NODE LOGIC   #\n",
    "###############################\n",
    "\n",
    "# The main router node uses the LLM to choose between tools or regular reply\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "@node\n",
    "async def router(state: GraphState):\n",
    "    user_input = state[\"user_input\"]\n",
    "\n",
    "    # Use the tool router to decide if we should call a tool\n",
    "    routing_decision = await tool_router.invoke(user_input)\n",
    "\n",
    "    if routing_decision.tool_calls:\n",
    "        # The tool router wants to use a tool\n",
    "        selected_tool = routing_decision.tool_calls[0][\"name\"]\n",
    "        tool_args = routing_decision.tool_calls[0][\"args\"][\"query\"]\n",
    "        print(f\"Router decision: calling tool {selected_tool} with query {tool_args}\")\n",
    "        return {\"next\": selected_tool, \"tool_args\": tool_args}\n",
    "    else:\n",
    "        # Otherwise, fallback to normal assistant\n",
    "        print(\"Router decision: fallback to normal assistant.\")\n",
    "        return {\"next\": \"assistant\"}\n",
    "\n",
    "##############################\n",
    "# STEP 4: ASSISTANT NODE     #\n",
    "##############################\n",
    "\n",
    "@node\n",
    "async def assistant(state: GraphState):\n",
    "    user_input = state[\"user_input\"]\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Basic LLM chat completion\n",
    "    response = await llm.ainvoke([{\"role\": \"user\", \"content\": user_input}])\n",
    "    messages.append(response.content)\n",
    "    return {\"messages\": messages, \"user_input\": user_input}\n",
    "\n",
    "#################################\n",
    "# STEP 5: TOOL NODE WRAPPING   #\n",
    "#################################\n",
    "\n",
    "# Wrap the tool function with ToolNode so it can be part of LangGraph\n",
    "joke_tool_node = ToolNode(joke_tool)\n",
    "\n",
    "@node\n",
    "async def joke_tool_handler(state: GraphState, tool_args: Annotated[str, \"tool_args\"]):\n",
    "    result = await joke_tool_node.ainvoke(tool_args)\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(f\"Joke: {result}\")\n",
    "    return {\"messages\": messages, \"user_input\": state[\"user_input\"]}\n",
    "\n",
    "##############################\n",
    "# STEP 6: BUILD THE GRAPH    #\n",
    "##############################\n",
    "\n",
    "graph_builder = StateGraph(GraphState)\n",
    "\n",
    "# Start from router\n",
    "graph_builder.add_node(\"router\", router)\n",
    "graph_builder.add_node(\"assistant\", assistant)\n",
    "graph_builder.add_node(\"joke_tool\", joke_tool_handler)\n",
    "\n",
    "# Edges:\n",
    "graph_builder.set_entry_point(\"router\")\n",
    "\n",
    "# Conditional routing: router decides where to go next\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    lambda x: x[\"next\"],  # The `next` value decides routing\n",
    "    {\n",
    "        \"assistant\": \"assistant\",\n",
    "        \"joke_tool\": \"joke_tool\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After assistant or joke_tool, go back to router (loop)\n",
    "graph_builder.add_edge(\"assistant\", \"router\")\n",
    "graph_builder.add_edge(\"joke_tool\", \"router\")\n",
    "\n",
    "# Finalize\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "##############################################\n",
    "# STEP 7: TESTING THE FLOW                   #\n",
    "##############################################\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def run_example():\n",
    "    state = {\"user_input\": \"Tell me a joke!\", \"messages\": []}\n",
    "\n",
    "    # Run a few steps in the loop\n",
    "    for step in range(3):\n",
    "        state = await graph.ainvoke(state)\n",
    "        print(f\"\\n--- Step {step+1} Output ---\")\n",
    "        for message in state[\"messages\"]:\n",
    "            print(message)\n",
    "        # Break loop if already satisfied\n",
    "        if len(state[\"messages\"]) > 0 and \"Joke:\" in state[\"messages\"][-1]:\n",
    "            break\n",
    "        state[\"user_input\"] = \"Thanks!\"\n",
    "\n",
    "asyncio.run(run_example())\n"
   ],
   "id": "52a0060056b2d21b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55f46025f0442ea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36f268a1735fe22a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
